\section{Реализация программного модуля захвата движений}

Реализация модуля захвата движений состоит в написании подрограмм на языке Python, объединяющихся в модуль и работающих внутри пакета Blender.

Blender имеет встроенный интерпретатор Python, который загружается при запуске Blender и остается активным во время его работы. Этот интерпретатор запускает скрипты для отрисовки пользовательского интерфейса, а также используется для некоторых внутренних инструментов Blender.

Интерпретатор языка Python, встроенный в пакет Blender, ничем не отличается от стандартного интерпретатора Python, который можно установить отдельно, поэтому при написании кода внутри Blender не стоит проблемы использования дополнительных модулей.

При необходимости, Blender может использовать и отдельно установленный на компьютере интерпретатор Python, для этого необходимо лишь удалить или переименовать папку с внутренним интерпретатором, расположенную в директории установки пакета Blender. При этом доступ к модулю BPY не теряется.

\subsection {Blender API}

Основой взаимодействия модуля, пакета Blender и объектов в нём является Blender Python API. API, доступ к которому предоставляется через модуль bpy, позволяет взаимодействовать с любыми объектами и данными внутри Blender. Подробнее о возможностях, доступных через API описано в пункте 2.1.2 второй главвы.

\subsubsection{Интерфейс, свойства и операторы}

Проектирование пользовательского интерфейса или оператора представляет собой, по сути, комбинацию создания свойств и наследования встроенных классов bpy.types (Панель, Оператор, Меню и т.д.).

Начнём с определения свойств. Свойства, по сути, являются "типами данных" и могут быть отображены в пользовательском интерфейсе для основных взаимодействий с пользователем. Доступ к значению каждого свойства можно получить практически из любой области Blender. 

Свойства могут быть:
\begin{itemize}
	\item BoolProperty - чекбокс
	\item FloatProperty или IntegerProperty - поле ввода типа float или int
	\item StringProperty для пользовательского ввода или пути до файла
	\item EnumProperty для выпадающего списка
\end{itemize}

Пример объявления свойств:

\begin{lstlisting}
from bpy.props import (BoolProperty,
					   IntProperty)

my_bool : BoolProperty(
	name="On or Off",
	description="Boolean property",
	default = False
	)

my_int : IntProperty(
	name = "Value",
	description="Integer property",
	default = 50,
	min = 0,
	max = 100
	)
\end{lstlisting}

Панели -  самый распространенный элемент пользовательского интерфейса. Где будет использоваться панель определяется типом bl\_space\_type Интерфейс Blender чувствителен к контексту, поэтому можно определить свойство bl\_context, чтобы использовать панель в одном из соответствующих режимов (Object Mode, Edit Mode, Pose Mode и т.д.).

Пример определения панели:
\begin{lstlisting}
class HelloWorldPanel(bpy.types.Panel):
	bl_idname = "OBJECT_PT_hello_world"
	bl_label = "Hello World"
	bl_space_type = 'PROPERTIES'
	bl_region_type = 'WINDOW'
	bl_context = "posemode"
	
	def draw(self, context):
	self.layout.label(text="Hello World")

bpy.utils.register_class(HelloWorldPanel)
\end{lstlisting}

Оператор - самая важная часть API. Операторы после регистрации в системе можно вызывать отовсюду через bpy.ops.IDNAME(). Кнопки на пользовательском интерфейсе так же вызывают определенные им операторы. Так же устроен и Blender, все существующие кнопки - это операторы, в основном написанные на Си или C++, но затем обёрнутые в Python.

Пример определения оператора:
\begin{lstlisting}
class HelloWorldMinimal(bpy.types.Operator):
	bl_idname = "wm.hello_world"
	bl_label = "Minimal Operator"
	
	def execute(self, context):
	# Report "Hello World" to the Info Area
	self.report({'INFO'}, "Hello World")
	
	return {'FINISHED'}
	
bpy.utils.register_class(HelloWorldMinimal)
\end{lstlisting}

На рисунке \ref{panex} представлен пример созданной панели с одной кнопкой-оператором.

\addimghere{panelexample}{0.7 }{Пример панели в интерфейсе}{panex}

Чтобы написанные модули или классы были доступны в Blender, а также была возможность их удаления из него, необходимо использовать функции register\_class и unregister\_class.

Регистрация класса в Blender приводит к загрузке определения класса в память, где класс становится доступным наряду с существующей функциональностью. После загрузки этого класса можно получить доступ к нему из подмодуля bpy.types, используя bl\_idname, а не оригинальное имя класса.

При загрузке класса Blender выполняет проверку на корректность, убедившись, что все необходимые свойства и функции найдены, что свойства имеют правильный тип, и что функции имеют нужное количество аргументов.

Пример регистрации и её отмены:
\begin{lstlisting}
import bpy

class SimpleOperator(bpy.types.Operator):
	.
	.

def register():
	bpy.utils.register_class(SimpleOperator)

def unregister():
	bpy.utils.unregister_class(SimpleOperator)

if __name__ == "__main__":
	register()
\end{lstlisting}


\subsection {Реализация оператора захвата мимики}

Прежде чем приступать к созданию интерфейса модуля, необходимо определить главный оператор - оператор захвата мимики.

Алгоритм работы оператора захвата мимики представлен на рисунке \ref{bldg}.

При запуске оператора начинается захват видеопотока с веб-камеры. Если потока нет или нажата кнопка СТОП из интерфейса, то выполнение оператора главного алгоритма прекращается. Далее происходит обработка полученного с потока кадра. Если на кадре найдено лицо - алгоритм переходит к расчетам необходимых параметров и выводу их на модель, затем переходит к обработке следующего кадра с потока камеры. Если лицо найдено не было, алгоритм перебирает кадры с потока до того момента, как лицо будет найдено. 

\addimghere{blsch}{1}{Алгоритм работы модуля}{bldg}

Главным классом файла оператора захвата мимики является класс MoCapOperator, отнаследованный от класса bpy.types.Operator. Это значит, что при регистрации данного класса, он будет доступен для вызова по bl\_idname из любого места в Blender, а впоследствии будет вызываться по кнопке из интерфейса.

Определяем путь до натренированной модели, и создаём объекты detector и predictor, для нахождения на изображении лиц и опорных точек:
\begin{lstlisting}
p = "shape_predictor_68_face_landmarks.dat" #
detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor(p)
\end{lstlisting}

Также определяем по каким точкам будет определяться поза головы. Шести точек (кончик носа, подбородок, углы глаз, углы рта) будет вполне достаточно для определения позы с необходимой точностью:
\begin{lstlisting}
model_points = numpy.array([
	(-0.005734, 0.0, 0.586476),             # konchik nosa
	(-0.005734, -0.09531, 0.513174),        # podborodok
	(0.007338, -0.05133, 0.657173),     # leviy ugol levogo glaza
	(-0.018807, -0.05133, 0.657173),      # praviy ugol pravogo glaza
	(0.017974, -0.073097, 0.562466),    # leviy ugo lrta
	(-0.029025, -0.073099, 0.563207)     # praviy ugol rta
	], dtype = numpy.float32)
\end{lstlisting}

Далее объявляем второстепенные функции, которые понадобятся для работы модуля или расчётов.

Функция moving\_window представляет собой реализацию скользящего среднего для заданного количества шагов, которая позволяет сгладить тряску опорных точек, возникающую при нахождении библиотекой DLib. Точки добавляются в массив атрибутов, а затем для каждой из точек в массиве расчитывается скользящее среднее:
\begin{lstlisting}
def rolling_window(self, name, length, value):
	if not hasattr(self, 'smooth'): #Soxdaem atribut smooth dlya klassa
		self.smooth = {}
	if not name in self.smooth:
		self.smooth[name] = numpy.array([value]) # dobavlyaem tochki
	else:
		self.smooth[name] = numpy.insert(arr=self.smooth[name], obj=0, values=value)
		if self.smooth[name].size > length:
			self.smooth[name] = numpy.delete(self.smooth[name], self.smooth[name].size-1, 0)
	sum = 0
	for val in self.smooth[name]:
		sum += val
	return sum / self.smooth[name].size #vozvraschaem srednee znachenie 
\end{lstlisting}

Для того, чтобы определить как за два следующих друг за другом кадра менялось расположение точек была написана функция get\_range. Данная функция, получая норму матрицы разностей координат двух точек, вычисляет насколько за два кадра эти точки друг от друга отдалились, возвращая значения от нуля до единицы:
\begin{lstlisting}
def get_range(self, name, value):
	if not hasattr(self, 'range'):
		self.range = {}
	if not name in self.range:
		self.range[name] = numpy.array([value, value])
	else:
		self.range[name] = numpy.array([min(value, self.range[name][0]), max(value, self.range[name][1])] )
	val_range = self.range[name][1] - self.range[name][0]
	if val_range != 0:
		return (value - self.range[name][0]) / val_range
	else:
		return 0
\end{lstlisting}

Норма матрицы позволяет примерно определить как далеко друг от друга находятся точки. Больше норма - дальше точки и наоборот. Определение значений, на которое каждый кадр необходимо сдвигать кости, было реализованно именно так, потому что это позволяет не зависеть от положения головы в кадре. Так как опорные точки всё-таки определяются по основным чертам лица, а лицо от головы в нормальных условиях неотделимо, то при выборе в качестве ориентира не положения точек относительно кадра, а положений пар точек относительно друг друга решается проблема непроизвольного движения головы во время работы программы и её перемещений по кадру в целом.

Попытки реализовать определение перемещений точек в кадре по их глобальным или локальным координатам давали удовлетворительный результат, только если голова в кадре стояла неподвижно, и двигалось только лицо.

Функция modal, в которой находится основной алгоритм является модальной, то есть которая выполняется, обрабатывая события до тех пор, пока не вернётся {'FINISHED'} или {'CANCELLED'}. Здесь функция будет вызываться до тех пор, пока номер текущего кадра анимации не станет равным номеру установленного последнего кадра.

На каждое событие берется кадр с потока камеры, отражается по вертикали для создания эффекта зеркала и переводится в оттенки серого. Далее детектор лиц библиотеки DLib находит на кадре лица, а предиктор определяет на найденном лице опорные точки. Тут же определяем опорные точки в массив image\_points, который далее будет передан как параметр для нахождения позы головы:
\begin{lstlisting}
_, image = self._cap.read()
image = cv2.flip(image, 1)
gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
rects = self.detector(gray, 0)

# Ischem litsa i opornie tichki
for (i, rect) in enumerate(rects):
	shape = self.predictor(gray, rect)
	shape = face_utils.shape_to_np(shape)
	
	image_points = numpy.array([shape[30],     # Nose tip - 31
								shape[8],      # Chin - 9
								shape[36],     # Left eye left corner - 37
								shape[45],     # Right eye right corne - 46
								shape[48],     # Left Mouth corner - 49
								shape[54]      # Right mouth corner - 55
								], dtype = numpy.float32)
\end{lstlisting}

Передаем в функцию cv2.solvePnP библиотеки OpenCV координаты точек на модели, точек на плоскости изображения с камеры, матрицу камеры и её коэффициент искривления (коэффициент искривления задаём нулевым, что отрицательно повлияет на точность расчетов, но полученный результат будет достаточным для использования в рамках модуля). Функция возвращает вектор поворота и вектор перемещения головы, а первое значение вектора поворота определим как first\_angle, что позволит далее поворачивать голову относительно этого начального угла: 

\begin{lstlisting}
if hasattr(self, 'rotation_vector'):
	(success, self.rotation_vector, self.translation_vector) = cv2.solvePnP(self.model_points, 
		image_points, self.camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE, 
		rvec=self.rotation_vector, tvec=self.translation_vector, useExtrinsicGuess=True)
else:
	(success, self.rotation_vector, self.translation_vector) = cv2.solvePnP(self.model_points, 
		image_points, self.camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE, 
		useExtrinsicGuess=False)
		
if not hasattr(self, 'first_angle'):
	self.first_angle = numpy.copy(self.rotation_vector)
\end{lstlisting}

Далее для выбранных костей передаём рассчитанные параметры. Для кости, отвечающей за повороты головы передаются углы поворота относительно изначального, для костей, связанных с опорными точками передаются сглаженные скользящим средним значения отдаления пар точек друг от друга.

Для поворота головы были выбраны две оси - ось Z, как ось кивка и ось X, как ось поворота головы вокруг своей оси. При добавлении оси наклонов головы влево и вправо управлять головой становится намного труднее, поэтому было реализовано вращение только лишь вдоль двух осей.

Дополнительно указываются коэффициенты. Для поворота головы  - это свойства  bpy.context.scene.my\_tool.z\_int и bpy.context.scene.my\_tool.x\_int, описанные в интерфейсе, которые управляют коэффициентами, на которые будут домножаться рассчитанные углы поворота головы. Для костей опорных точек коэффициенты подбираются в результате эксперимента и вписываются неизменными в программный модуль:
\begin{lstlisting}
bones["spine_3"].rotation_euler[0] = self.rolling_window("h_x", 3, (self.rotation_vector[0] - self.first_angle[0])) / -bpy.context.scene.my_tool.z_int   # Naklon vlevo/vpravo
bones["spine_3"].rotation_euler[1] = self.rolling_window("h_y", 3, -(self.rotation_vector[1] - self.first_angle[1])) / -bpy.context.scene.my_tool.x_int  # Povorot golovy vokrug svoeu osi

bones["mouth_SKC.R"].location[0] = self.rolling_window("m_r", 3, -(self.get_range("mouth_right", numpy.linalg.norm(shape[54] - shape[48])) - 0.5) * -0.04) #Ugolki rta
bones["mouth_SKC.L"].location[0] = self.rolling_window("m_l", 3, (self.get_range("mouth_left", numpy.linalg.norm(shape[54] - shape[48])) - 0.5) * -0.04)
\end{lstlisting}

Финальным шагом работы оператора является запись новых положений и углов костей в ключи анимации. При индексе равном минус одному запись происходит по всем осям:
\begin{lstlisting}
bones["spine_3"].keyframe_insert(data_path="rotation_euler", index=-1)
bones["mouth_SKC.R"].keyframe_insert(data_path="location", index=-1)
bones["mouth_SKC.L"].keyframe_insert(data_path="location", index=-1)
\end{lstlisting}

Таким образом была рассмотрена реализация оператора захвата мимики. После регистрации данного опреатора в Blender, он будет доступен через вызов wm.mocap\_operator в API. 

Полный листинг кода оператора приведён в приложении А.


\subsection {Реализация пользовательского интерфейса}

Реализация оператора модуля захвата мимики позволяет начать реализацию интерфейса.

В ходе разработки основного оператора модуля появилась необходимость в точной подстройке коэффициентов поворота головы. Если установленных при написании оператора параметров для смещения костей оказалось достаточно для корректной работы на большинстве расстояний от камеры, то в случае с вращениями головы требуется более точная настройка.

Необходимые коэффициенты вращения объявляются как свойтсва c плавающей точкой:
\begin{lstlisting}
class MyProperties(PropertyGroup):
	x_int: FloatProperty(
		name = "X coefficient",
		description="Rotation coefficient along X",
		default = 1,
		min = 0.1,
		max = 10
		)
	
	z_int: FloatProperty(
		name = "Z coefficient",
		description="Rotation coefficient along Z",
		default = 1,
		min = 0.1,
		max = 10
		)
\end{lstlisting}

Далее необходимо определить вспомогательный оператор для сброса положений и вращений всех костей модели. Данный оператор нужен для быстрого возвращения модели к исходному виду, что делает начало работы с оператором захвата мимики удобнее, так как в исходном положении модель ближе всего соответсвует лицу, не выражающему никаких эмоций.

Данный опретор циклом проходит по всем костям объекта и устанавливает их положение и поворот в ноль. После регистрации данный оператор можно будет вызвать через wm.reset\_bone\_position в API:
\begin{lstlisting}
class WM_OT_ResetBones(Operator):
	bl_label = "Reset Bones"
	bl_idname = "wm.reset_bone_position"
	
	def execute(self, context):
		ob = bpy.data.objects['armature_Danny']
		bpy.context.view_layer.objects.active = ob
		bpy.ops.object.mode_set(mode='POSE')
		flag = 0
		
		for pbone in bpy.context.active_object.pose.bones:
		pbone.location = (0, 0, 0)
		pbone.rotation_euler[0] = 0
		pbone.rotation_euler[1] = 0
		pbone.rotation_euler[2] = 0
	
	return {'FINISHED'}
\end{lstlisting}

Так как все основные операторы и свойства определены, то можно приступать к описанию интерфейса.

Объявляем класс панели OBJECT\_PT\_MocapPanel, наследующийся от класса Panel, и объявляем параметры, которые определяют название панели модуля, в каком пространстве Blender он будет находиться, его имя для вызова из API и в какой панели настроек он будет располагаться.

\begin{lstlisting}
class OBJECT_PT_MocapPanel(Panel):

	bl_label = "MoCap settings" # Panel name
	bl_idname = "OBJECT_PT_custom_panel" # API name
	bl_space_type = "VIEW_3D" # panel 3D Viewport
	bl_region_type = "UI" # region of blender ui for panel
	bl_category = "MoCap" # panel tab name
	bl_context = "posemode" # context
\end{lstlisting}

После указания параметров панели необходимо вызвать функцию draw для отрисовки элементов интерфейса.

В функции draw определяем, где на панели будут отрисовываться поля и кнопки и поочередно их на нее добавляем. Положение кнопок и полей на макете зависит от порядка их добавления в коде:
\begin{lstlisting}
def draw(self, context):
	layout = self.layout
	scene = context.scene
	mytool = scene.my_tool
	
	layout.prop(mytool, "x_int")
	layout.prop(mytool, "z_int")
	layout.separator()
	layout.operator("wm.reset_bone_position")
	layout.separator()
	layout.operator("wm.mocap_operator")
	layout.separator()
\end{lstlisting}

Для свойств указываем к какой группе они относятся и их названия в этой группе, а для кнопок указываем какие операторы они будут вызывать по нажатию.

Для того чтобы панель и объявленные для неё классы появились в системе, необходимо реализовать функцию регистрации и отмены регистрации классов в Blender.

Для этого добавляем все классы в кортеж classes и циклом для каждого из классов в кортеже вызываем метод register\_class() или unregister\_class():
\begin{lstlisting}
classes = (
	MyProperties,
	WM_OT_ResetBones,
	OBJECT_PT_MocapPanel
	)

def register():
	from bpy.utils import register_class
	for cls in classes:
		register_class(cls)

	bpy.types.Scene.my_tool = PointerProperty(type=MyProperties)

def unregister():
	from bpy.utils import unregister_class
	for cls in reversed(classes):
		unregister_class(cls)
	del bpy.types.Scene.my_tool
\end{lstlisting}

Полный листинг кода интерфейса представлен в приложении А.

Интерфейс реализованного модуля представлен на рисунке \ref{panl}:  
\addimghere{panel}{0.6}{Интерфейс программного модуля захвата мимики}{panl}

Реализованный модуль находится в контексте Pose Mode в N-меню и имеет свою собственную вкладку в интерфейсе. Непосредственно на панели располагаютя поля для коэффициентов вращения головы, кнопка для установки костей в начальные положения и кнопка начала работы с главным оператором.

\subsection {Эксперимент}

Для того, чтобы определить работоспособность программного модуля и наилучший способ обращения с ним необходимо провести эксперимент.

\subsubsection {Технические показатели}

Характеристики компьютера, на котором проводится эксперимент:
\begin{itemize}
	\item ОС: Windows 10
	\item Оперативная память: 12 GB
	\item Видеокарта: Geforce 940m 2gb
	\item Процессор: Core i5 4210u 2.70 GHz
\end{itemize}


Средняя частота кадров в процессе работы модуля равна 10 кадрам в секунду (рис. \ref{fpss}). Минимально - 8 кадров в секунду, максимально - 12. Основное препятствие для получения как минимум кинематографичного показателя в 24 кадра в секунду - слабый процессор, на который ложится просчёт алгоритмов и нахождение точек.

Бибилиотека DLib справляется с расчётом опорных точек лучше, чем аналогичные средства библиотеки OpenCV и при работе отдельно от Blender выдаёт 25-30 кадров в секунду, что близко или равно возможностям камеры (30 кадров в секунду). Однако, внутри пакета Blender используется движок рендера в реальном времени Eevee и используются вызовы API для работы основного оператора, что негативно влияет на количество кадров  в секунду.


\addimghere{fps}{0.6}{Счётчик кадров в секунду в интерфейсе Blender}{fpss}

\subsubsection {Использование программного модуля}

Проверим работу модуля на разном расстоянии от камеры: 

Чем больше занимает лицо на кадре, тем точнее библиотека DLib находит опорные точки. Поэтому на расстоянии головы в 25 сантиметрах от камеры расчёты значений, а следовательно и захват мимики получаются самыми точными (рис. \ref{twenfiv}).

Из минусов такого расстояния можно выделить возможный дискомофорт в использовании модуля пользователем, так как камеру приходится держать достаточно близко к лицу, а при работе с ноутбуком без внешней камеры, работать на таком близком расстоянии весьма неудобно.

\addimghere{25cm}{1}{Использование модуля на расстоянии 25 саниметров от лица пользователя}{twenfiv}

На расстоянии в 50 сантиметров (рис. \ref{fifty}), что в два раза больше, чем в предыдущем опыте, пользоваться системой становится заметно удобнее, при этом падение в качестве распознавания опорных точек минимально заметно.

\addimghere{50cm}{1}{Использование модуля на расстоянии 50 саниметров от лица пользователя}{fifty}

Похожая ситуация сохраняется и на расстоянии в 75 сантиметров (рис. \ref{sevfiv}). Использование системы пользователем не вызывает у него дискомфорта, а распознавание опорных точек в библиотеке DLib всё еще справляется со своей задачей. Все основные черты, как глаза, брови, рот и уголки рта различимы и нормально проходят обработку алгоритмами.

\addimghere{75cm}{1}{Использование модуля на расстоянии 75 саниметров от лица пользователя}{sevfiv}

Начиная с расстояния в 1 метр и более, безошибочно удается распознать только лишь позу головы (рис. \ref{meter}). Отдельные же точки уже находятся слишком близко друг к другу и не могут быть использованы для точного определения главных черт лица. Также на таком расстоянии начинает сильно проявляться эффект тряски точек, который не может до конца подавить реализованный алгоритм скользящего среднего.

\addimghere{1m}{1}{Использование модуля на расстоянии 1 метра от лица пользователя}{meter}

Стоит отметить, что наиболее удобное расстояние для использования модуля лежит в пределах от 40 до 75 сантиметров, что совпадает с рекомендованными СанПиН правилами работы с компьютером \cite{sanpindoc} (рис. \ref{sanpic}).

\addimghere{sanpin}{1}{Работа с компьютером по СанПиН}{sanpic}

Что касается освещенности, то для минимально корректной работы модуля на расстоянии в 50 сантиметров хватает подсветки монитора на максимальной яркости, при значениях подсветки меньше модуль может не определить опорные точки. 

Лучше всего программный модуль будет работать при полном комнатном освещении. В этом случае максимальна точность определения положений опорных точек, что сильно уменьшает эффект их тряски.

На рисунке \ref{ligh} представлены возможности работы модуля при разных уровнях освещения:

\addimghere{light}{0.5}{Примеры нахождения опорных точек при различной освещенности}{ligh}.

\subsubsection {Вывод по итогам эксперимента}
По итогам эксперимента было выяснено, что данный программный модуль является достаточно ресурсоемким и процессорозатратным, но может выдавать приемлемый результат и на относительно слабой конфигурации.

В процессе тестирования готового модуля обнаружилось, что из-за относительно невысокого показателя кадров  в секунду моргание может не передаваться на модель по причине  того, что процесс моргания происходит достаточно быстро и может не попасть в промежуток захвата кадра.

Лучше всего себя модуль показывает при расстоянии камеры от пользователя в диапазоне от 40 до 75 сантиметров, что не только удобно при использовании, но и, согласно СанПиН, минимально вредит здоровью при длительном использовании.

Также для достижения наилучших результатов необходим хороший уровень освещенности в помещении, где производится захват мимики. Чем ниже освещенность, тем ниже точность работы модуля. 

\subsection{Руководство пользователя}
\subsubsection {Установка зависимостей}

Для корректной работы модуля необходимо для внутреннего интерпретатора языка Python пакета Blender установить библиотеки:

\begin{itemize}
	\item opencv-contrib-python \cite{ocvcontr}
	\item dlib \cite{dlibpypi}
	\item numpy \cite{numpypypi}
\end{itemize}

Также необходимо скачать натренированную модель \cite{gitdat}.

\subsubsection {Подготовка программного модуля}

В файле oper.py в 15 строке необходимо прописать путь до натренированной модели (пункт 2.4.2) (рис. \ref{datf}).

\addimghere{datfile}{0.7}{Пример пути до файла натренированной модели}{datf}.

В строках с 116 по 155 установить названия костей в соответствии с их наименованиями в модели.


\subsubsection {Установка программного модуля}

Для создания установочного архива программного модуля, необходимо добавить оба файла проекта в архив с расширением .zip (рис. \ref{zip}).

\addimghere{ziplock}{0.4}{Файлы программного модуля и установочный архив}{zip}

Далее, в пакете Blender необходимо установить полученный архив. Для этого необходимо открыть настройки, перейдя по пути Edit - Preferences в главном меню, и выбрать вкладку Add-ons, затем нажать кнопку Install и указать путь до программного модуля (рис. \ref{addinstall}).

\addimghere{installation}{0.7}{Установка программного модуля}{addinstall}

После этого во вкладке установленного модуля необходимо установить чекбокс, включающий его, и модуль появится в контексте Pose Mode (рис. \ref{onadd}).

\addimghere{onaddon}{1}{Включение программного модуля}{onadd}

Альтернативно, модуль можно запустить из интефрейса скриптинга, загрузив в текстовый редактор коды обоих файлов и нажав кнопку Run Script (рис. \ref{altinst}).

\addimghere{altinstall}{1}{Альтернативный способ установки модуля}{altinst}

\subsubsection {Взаимодействие с интерфейсом}

Интерфейс модуля доступен только из режима Pose Mode и находится на вкладке MoCap.

Поля ввода коэффициентов служат для настройки вращения головы вдоль осей X и Z. После запуска оператора захвата мимики следует подстроить коэффициенты до достижения желаемого результата.

Кнопка Reset Bones служит для установки значений и перемещений всех костей модели в ноль. Её следует нажимать перед каждым запуском захвата мимики для избежания неточности при передаче расчётных параметров на модель. 

Кнопка Start MoCap Operator служит для запуска захвата мимики и её передачи на модель.

Остановка же захвата производится по нажатию правой кнопки мыши.

На рисунке \ref{man} изображен интерфейс модуля с пояснениями.

\addimghere{manual}{0.8}{Интерфейс модуля с пояснениями}{man}

\clearpage
