\section{Проектирование программного модуля захвата движений}

Проектирование программного модуля захвата движений предполагает разработку в несколько этапов:
\begin{itemize}
	\item анализ доступных средств Blender;
	\item выбор библиотек компьютерного зрения;
	\item выбор объекта, с которым будет взаимодействовать программного модуль;
	\item определение алгоритмов, по которым будет работать программный модуль;
	\item написание и отладка программного модуля.
\end{itemize}


\subsection{Анализ доступных средств Blender}

Кроме стандартных для трехмерных графических пакетов функций, в Blender стандартно поставляется текстовый редактор и интерпретатор языка Python 3 \cite{blenderprogbook}.

Главной частью выполнения скриптов является модуль bpy, позволяющий любое действие, которое можно было бы произвести при помощи интерфейса, выполнить программно.

\subsubsection{Интерфейс}
Интерфейс для скриптинга (рис. \ref{scriptinterf}) состоит из:
\begin{itemize}
	\item текстового редактора;
	\item интерактивной консоли;
	\item журнала команд.
\end{itemize}
\addimghere{scriptinginterface}{1}{Интерфейс панели скриптинга}{scriptinterf}

Текстовый редактор позволяет создавать и редактировать как скрипты на языке python, так и любые другие текстовые файлы

Интерактивная консоль представляет собой окружение, схожее с интерактивной консолью python. Консоль никак не связана с кодом, запускаемым из текстового редактора, но и консоль, и редактор имеют полный доступ к глобальным данным Blender, содержащимся в модуле bpy и его подмодулях.

Журнал команд показывает, какие вызовы были сделаны интерфейсом программы во время использования. Просмотр вывода этого окна сильно упрощает изучение API и эксперименты с ним.

\subsubsection{Модуль BPY}

Главным модулем в Blender является bpy \cite{blenderapiref}. Данный модуль позволяет взаимодействовать со всеми данными Blender, его классами и функциями. 

Подмодуль bpy.ops содержит операторы. Операторы это основные функции для взаимодействия с объектами, подобно тому как художник в Blender манипулирует объектами через интерфейс.
Два самых важных класса в этом модуле -  bpy.ops.object и bpy.ops.mesh. Класс object содержит функции для управления объектами в целом, а также общие функции. Класс mesh содержит непосредственно функции для редактирования точек, рёбер, полигонов, обычно в режиме Edit Mode.

Подмодуль bpy.context используется для доступа к объектам и областям Blender по различным их статусам.

Подмодуль bpy.data даёт доступ к внтренним данным Blender. Так например  bpy.data.objects содержит все данные, определяющие форму объекта и его положение в пространстве.

Подмодуль bpy.props содержит как стандартные свойства (типы данных), которые можно использовать в Blender, так и даёт возможность определять свои собственные.

Подмодуль bpy.utils содержит функции Blender, не связанные с его объектами и данными, как например функции для загрузки модулей и регистрирования их в системе.

\subsection{Выбор библиотек компьютерного зрения}
OpenCV \cite{ocvsite} является самой популярной библиотекой компьютерного зрения. Она включает в себя как огромное количество готовых функций, так и большую поддержку со стороны разработчиков и сообщества пользователей. Благодаря обширной документации не представляет труда разобраться в необходимых нюансах использования данной библиотеки.

Поэтому из-за широкой поддержки, возможности захвата видеопотока и множества готовых функций, основной библиотекой компьютерного зрения был выбран именно OpenCV.

Двумя основными библиотеками, которые можно использовать для определения опорных точек являются OpenCV и DLib \cite{dlibsite}. После тестирования и сравнения доступных методов этих библиотек (Facemark API \cite{facemark} и DLib Face landmark detection \cite{dlibfaceland}), в качестве библиотеки для нахождения опорных точек была выбрана библиотека DLib. Именно она показала как наилучшее качество нахождения точек, так и лучшую производительность.

Таким образом связка библиотек OpenCV и DLib была выбрана в качестве основных, используемых в проекте, ввиду наличия наиболее подходящего функционала и хороших результатов производительности.

\subsection{Выбор объекта с которым будет взаимодействовать программный модуль}


Так как разрабатываемая система является универсальной и не зависит от формы модели, то для корректной её работы необходимо только наличие у модели контроллеров-костей, которые будут управлять анимацией объекта.

В качестве рабочего объекта была взята модель из видео \cite{redditguy} (рис. \ref{dannyh}), демонстрирующего работу встроенных в пакет Blender средств трекинга и анимации.

\addimghere{dannyhead}{0.8}{Готовая модель головы}{dannyh}

Для корректного взаимодействия костей с программой необходима первоначальная их настройка.

Для того, чтобы избежать артефактов или некорректного поведения, на каждую кость по отдельности необходимо наложить модификаторы ограничители - "Limit location" и "Limit rotation". Первый модификатор ограничивает перемещение, второй модификатор ограничивает поворот.

Для добавления модификатора "Limit Location" выбирается кость в режиме Pose Mode и во вкладке Bone Constraint Properties выбирается нужный ограничитель. В данном модификаторе можно установить ограничение по перемещению для кости по любой из трёх осей, а также выбрать систему координат, в которой будет работать модификатор и коэффициент усиления Influence (рис. \ref{limloc}). На выбор доступны локальная, локальная родительская, локальная относительно всей структуры костей, мировая системы координат.

\addimghere{limitloc}{1}{Окно настроек модификатора Limit Location}{limloc}

Аналогично происходит работа с модификатором Limit Rotation. Для выбранной кости в градусах указывается ограничение вращения по часовой и против часовой стрелок для осей x, y и z, система координат и коэффициент усиления (рис. \ref{limrot}).

\addimghere{limitrot}{1}{Окно настроек модификатора Limit Rotation}{limrot}

Данные модификаторы как ограничивают мимику, позволяя установить её параметры, соответствующими человеческой, так и  помогают избежать артефактов. На рисунке \ref{goodf} представлен вариант модели с правильно настроенной мимикой - все части лица выглядят органично и отсутствуют артефакты.

\addimghere{goodface}{1}{Пример хорошо настроенной модели}{goodf}

На рисунке \ref{badf} видно, что при неправлиьной настройке или её отсутсвии на модели могут проявляться артефакты, а сама мимика модели не будет соответствовать возможностям мимики человека.

\addimghere{badface}{1}{Пример плохо настроенной модели}{badf}




\subsection{Определение алгоритмов, по которым будет работать программный модуль}

\subsubsection{Определение позы головы}

В данной работе необходимо решить две проблемы - проблему определения позы головы и проблему корреляции найденных опорных точек лица актера и точек трехмерной модели.

Определение позы головы известно как проблема Perspective-n-Point, в которой цель - это найти позу объекта, имея откалиброванную камеру и зная координаты точек в трехмерном пространстве и соответсвующих им проекций на двумерном изображении.

Относительно камеры у трехмерного объекта есть два вида движений:

\begin{itemize}
	\item Параллельный перенос - движение камеры из текущей точки в трехмерном пространстве в новую;
	\item Поворот - может быть представлен углами Эйлера, матрицей поворота или направлением вращения и углом.
\end{itemize}

Для того чтобы вычислить трехмерную позу объекта (головы) на изображении надо:

\begin{itemize}
	\item 2D координаты нескольких точек - в данной работе используются координаты точек, полученных библиотекой DLib;
	\item 3D координаты тех же точек - используем координаты модели головы в Blender.
\end{itemize}

Заметим, что для корреткной работы точки должны находиться в одной системе координат - мировой.

Зная поворот и перемещение точек в мировых координатах, мы можем рассчитать их новые значения в координатах камеры. Трехмерные точки координат камеры могут быть спроецированы на плоскость изображения (его систему координат), зная параметры камеры (оптический центр, фокусное расстояние и так далее).

\addimghere{coordinates}{1}{Координатная модель системы}{coords}

На рисунке \ref{coords}, точка $o$ это центр камеры, а плоскость - плоскость её изображения. Нас интересует, какие уравнения определяют проекцию $p$ трехмерной точки $P$ на плоскость изображения.

В OpenCV для оценки позы можно использовать функцию solvePnP.

solvePnP расчитывает позу объекта по соответствию точек в 3D системе координат модели и 2D системе координат изображения с камеры. В этом случае функция находит такую позу, которая минимизирует ошибку повторения, т.е. сумму квадратов расстояний между наблюдаемыми проекциями на изображении и проектируемыми точками.


\subsubsection{Определение опорных точек}

Для нахождения на изображении с камеры опорных точек используется библиотека DLib.

Опорные точки используются, чтобы локализовать и представить важные области лица, такие как:
\begin{itemize}
	\item Глаза;
	\item Брови;
	\item Нос;
	\item Рот;
	\item Подбородок.
\end{itemize}

Обнаружение лицевых опорных точек является подмножеством проблемы прогнозирования формы. Получив входное изображение (и, как правило, ROI (region of interest - ROI), определяющее интересующий объект), предиктор формы пытается локализовать ключевые точки интереса на изображении.

Нахождение опорных точек состоит из двух шагов - нахождения на изображении лица и нахождения непосредственно самих ключевых точек на ROI найденного лица.

Для нахождения на изображении с камеры региона лица был выбран встроенный в библиотеку OpenCV предварительно обученный специально для задачи обнаружения лица метод, использующий гистограммы направленных градиентов в сочетании с методом опорных векторов.

Детектор опорных точек, включенный в библиотеку DLib, представляет собой реализацию "One Millisecond Face Alignment with an Ensemble of Regression Trees", выполненную Каземи и Салливаном в 2014 году \cite{regtrees}.

Исходя из тренировочных данных (рис. \ref{ibugpic}) (в работе используется модель, натренированная на датасете  iBUG 300-W \cite{ibug} в 68 точек), алгоритм по методу деревьев регрессии обучается оценивать положение лицевых опорных точек непосредственно по интенсивности пикселей (т.е. "выделение признаков" не происходит).

\addimghere{ibugpicture}{1}{Пример размеченных изображений в датасете iBUG 300-W}{ibugpic}

Конечный результат - детектор лицевых опорных точек, который может быть использован для обнаружения опорных точек в режиме реального времени с высоким качеством прогнозирования.


\subsection{Проектирование архитектуры системы захвата мимики лица}

Желаемая архитектура системы представлена на рис. \ref{arc}. Модуль должен захватывать поток с веб-камеры, обрабатывать его с помощью библиотек компьютерного зрения и по полученным данным управлять мимикой модели в сцене.

\addimghere{arch}{1}{Архитектура системы}{arc}

Архитектуру же самого модуля (рис. \ref{arcp}) можно разделить на две составляющие:
\begin{itemize}
	\item Интерфейс;
	\item Система управления;
\end{itemize}

В интерфейсе находятся кнопки, запускающие различные операторы и поля для ввода параметров. Пользователь взаимодействует с интерфейсом, запуская главный алгоритм модуля и устанавливая для него коффициенты.

В системе управления находятся операторы, вызываемые кнопками интерфейса через API Blender.

Прямой связи между интерфейсом и системой управления нет. Так например кнопки вызывают операторы, находящиеся в области видимости всего пакета Blender, через API, а значения полей ввода интерфейса являются отдельными объектами в Blender, которые доступны операторам только лишь через API.

\addimghere{archpl}{1}{Архитектура программного модуля}{arcp}

Рассмотрим представленную на рисунке \ref{arc} архитектуру более подробно.

Видеопоток с веб-камеры, как показано на рисунке \ref{sc1}, по шине USB передаётся в компьютер. Параметры камеры для работы могут быть любыми, если на полученном изображении будет чётко видно лицо. От разрешения камеры будет зависеть точность распознавания опорных точек, но вместе с увеличением разрешения будет значительно падать и производительность, поэтому камеры с разрешением 800 на 600 точек вполне хватит как для достаточно точного определения точек, так и для достаточной производительности.

Альтернативно, для работы модуля подойдет заранее подготовленный видеоролик или секвенция изображений, но в данной работе будет реализована только работа с видеопотоком с камеры.

\addimghere{schema1}{1}{Передача видеопотока в компьютер}{sc1}

Далее видеопоток перехватывается библиотекой OpenCV и разбивается на отдельные кадры с помощью её стандартных средств \ref{sc2}. Можно подметить, что для лучшего результата работы встроенного средства трекинга Blender, подготовленное видео также необходимо разбить на последовательность кадров.

\addimghere{schema2}{1}{Разбор видеопотока на кадры}{sc2}

Следующим этапом (рис. \ref{sc3}) при помощи библиотек OpenCV и DLib определяются положение головы и опорных точек. Для определения положения головы в пакете OpenCV есть стандартные средства, решающие проблему Perspective-n-Point - определения позы по n 3D точкам и их проекции на 2D изображение, а для нахождения опорных точек в DLib существуют функции, которые по готовой натренированной модели находят на лице нужные точки. 

\addimghere{schema3}{1}{Кадры последовательно подаются на обработку алгоритмами}{sc3}

Финальным этапом является передача полученных данных в Blender и их использование через Blender API для процесса анимирования (рис. \ref{sc4}). Одной из главных особенностей Blender является наличие широкого и достаточно низкоуровнего API, что позволяет практически любое действие выполнить посредством вызова функций API.

Назначенные кости будут получать данные о новых координатах и углах вращения от соответствующих опорных точек на лице и рассчитанных коэффицентах.

\addimghere{schema4}{1}{Передача рассчитанных параметров в Blender}{sc4}
 
\subsubsection{Планирование интерфейса программного модуля}

Меню модуля должно находиться в N-панели Blender в отдельной вкладке.

На панели модуля должны располагаться:

\begin{itemize}
	\item Поле ввода коээфицента поворота головы вдоль оси X;
	\item Поле ввода коээфицента поворота головы вдоль оси Y;
	\item Кнопка запуска модуля;
	\item Кнопка для сброса значений поворота и перемещения для всех костей модели.
\end{itemize}

Примерный вид модуля в интерфейсе Blender представлен на рисунке \ref{interf}.

\addimghere{interface}{1}{Примерный вид интерфейса модуля}{interf}


\subsubsection{Технические требования к программному модулю}

Для удобства модуль должен состоять из двух файлов - файла, добавляющего пользовательский интерфейс и файла оператора, вызываемого и настраиваемого через кнопки интерфейса.

Минимальные системные требования:
\begin{itemize}
	\item Версия Blender: 2.8 или новее;
	\item ОС: любая, удовлетворяющая условиям запуска пакета Blender и установки библиотек OpenCV и DLib;
	\item Оперативная память: 2 GB ОЗУ;
	\item Видеокарта: 1GB RAM, OpenGL 3.3;
	\item Место на диске: 500 MB.
\end{itemize}

\clearpage
